エンジニア向け：実装における3つの重要ポイント
① IssueOpsによるパラメータの安全な受け渡し
GitHub Pagesからは直接GitHub Actionsを起動させるのではなく、GitHub API経由でIssueを作成させます。そのIssueの本文に START_ROW や END_ROW を記載し、Actions内で actions/github-script を使ってパース（抽出）することで、安全かつ動的にパラメータをPythonへ渡せます。

② if: always() を活用した途中データの保護
スクレイピング処理を行う Run Scraping Script の次のステップに if: always() を設定しています。これにより、万が一処理が6時間のタイムアウトに達して強制終了されたり、途中でエラーが起きたりした場合でも、**それまでに output_data/ フォルダへ書き出されたデータは必ずGitHub上に保存（アップロード）**されます。

③ Pythonスクリプト側の実装要件（ご留意事項）
このWorkflowを最大限活かすため、実行されるPythonスクリプト（src/scraper.py）は以下のように設計しておくことを推奨します。

受け取った START_ROW から END_ROW までの処理をループで行う。

メモリ不足やタイムアウトに備え、データを100件〜500件など一定数取得するごとに output_data/ 配下にCSVやJSONとしてこまめにファイル出力する。

次回再実行時に、出力済みのファイルを読み込んで「どこまで終わったか」を判定し、続きから処理を開始できる（レジューム機能）ようにする。
